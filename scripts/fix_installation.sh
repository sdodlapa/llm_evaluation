#!/bin/bash
# Fix version conflicts and install remaining packages

echo "ðŸ”§ Fixing version conflicts..."

# Fix setuptools version for vLLM compatibility
crun -p ~/envs/llm_env pip install "setuptools>=77.0.3,<80"

# Install compatible PyTorch version for vLLM
echo "ðŸ”¥ Installing compatible PyTorch for vLLM..."
crun -p ~/envs/llm_env pip install torch==2.8.0 torchvision==0.23.0 torchaudio==2.8.0 --index-url https://download.pytorch.org/whl/cu121

# Install vLLM
echo "âš¡ Installing vLLM..."
crun -p ~/envs/llm_env pip install vllm

# Install flash-attention with specific CUDA flags
echo "âš¡ Installing flash-attention..."
crun -p ~/envs/llm_env pip install flash-attn --no-build-isolation

# Skip auto-gptq for now due to compilation issues, install alternatives
echo "ðŸ—œï¸ Installing quantization libraries (skipping auto-gptq)..."
crun -p ~/envs/llm_env pip install bitsandbytes optimum

# Install transformers ecosystem
echo "ðŸ¤– Installing transformers..."
crun -p ~/envs/llm_env pip install transformers tokenizers accelerate safetensors huggingface-hub

# Install basic evaluation packages
echo "ðŸ“Š Installing evaluation packages..."
crun -p ~/envs/llm_env pip install datasets evaluate numpy pandas matplotlib seaborn tqdm rich

echo "âœ… Fixed installation complete!"